{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d633eb-0f42-4b25-9fc4-1175d48bfce6",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ab841-2d2c-43b7-bad7-f997366ca3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781145b-741d-4fd8-bdf4-9b57857563b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\tubs\\OneDrive\\Desktop\\Code\\Heron Data\\join-the-siege\\files\\synthesised_training_data\"\n",
    "\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    file_list.extend([os.path.join(root,file) for file in files])\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf49039-c097-4444-921e-e5a72db914ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6eb821-26a7-4f06-8d83-2b5aff160a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contents = {}\n",
    "for file in file_list:\n",
    "    if file.endswith('.txt'):\n",
    "        with open(file, 'r') as f:\n",
    "            file_contents[file] = f.read()\n",
    "    if file.endswith('.docx'):\n",
    "        doc = docx.Document(file)\n",
    "        word_text = '\\n'.join([p.text for p in doc.paragraphs])\n",
    "        file_contents[file] = word_text\n",
    "len(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48abf2-cd70-419e-87c1-28e994ff9dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d696d295-6bcf-4f5b-92a8-35c1832cc306",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_df = pd.DataFrame.from_dict(file_contents, orient='index').reset_index()\n",
    "columns = ['file_path', 'file_contents']\n",
    "files_df.columns = columns\n",
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8904f-e8c8-49e9-a1bb-bd2d7868444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a0508-6a52-42d9-902a-632a6bee8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df['file_category'] = files_df['file_path'].apply(lambda x: os.path.split(os.path.split(x)[0])[1])\n",
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c4b34-7f9c-4be7-83c6-120e21ba4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df['file_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed236c0-d105-47a9-8767-5eb0d6b9c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df['file_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc9778-0b39-4218-85ca-111909636c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_label_dict = {\n",
    "    'acad_rep_docx': 'academic_report'\n",
    "    , 'bus_rep_docx': 'business_report'\n",
    "    , 'eml_txt': 'email'\n",
    "    , 'fml_let_docx': 'formal_letter'\n",
    "}\n",
    "\n",
    "files_df['file_label'] = files_df['file_category'].apply(lambda x: category_to_label_dict[x])\n",
    "files_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e837af-a5ef-4e96-9da3-bd3f6daaa220",
   "metadata": {},
   "source": [
    "# 2. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cdc073-e25a-43ca-8639-46dc585dc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260fbabc-01e7-432c-ba1c-989277241d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_labels_df = files_df[['file_contents','file_label']]\n",
    "columns = ['text','label']\n",
    "contents_labels_df.columns = columns\n",
    "contents_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764c31b-a936-4890-8a3f-ce07ecb80e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(contents_labels_df['text'], contents_labels_df['label'])\n",
    "\n",
    "print(f'''\n",
    "    Training Set:   {len(train_x)}\n",
    "    Validation Set: {len(valid_x)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c00ac3-c7ef-4fa7-bf58-67f1c866da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac9ec2-3780-479d-8b34-ea7dc4a384d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y_encoded = encoder.fit_transform(train_y)\n",
    "valid_y_encoded = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182fdc0-cbaa-4c75-b73d-3751a4014832",
   "metadata": {},
   "source": [
    "### Map Labels to Encoded Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a924fb-c4e8-4528-9573-a85067c0a0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoding_zip = list(zip(valid_y_encoded.tolist(), list(valid_y)))\n",
    "encoding_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8634d40-13ec-46c1-8ff6-a4c77489087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_map = dict(set(encoding_zip))\n",
    "encoding_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac64b83-75ac-4455-ac63-2fba2d3c18eb",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e8f6b-4999-416f-8358-97d7b2c00d5e",
   "metadata": {},
   "source": [
    "## 3.1. Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679ef70-091d-4979-bd9c-02d103b477b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(contents_labels_df['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "train_x_count =  count_vect.transform(train_x)\n",
    "valid_x_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97032f6a-9cc0-4480-855f-9e3c18a78b2e",
   "metadata": {},
   "source": [
    "## 3.2. TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d8524-307f-4035-8750-3a6bbe52006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(contents_labels_df['text'])\n",
    "train_x_tfidf =  tfidf_vect.transform(train_x)\n",
    "valid_x_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(contents_labels_df['text'])\n",
    "train_x_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "valid_x_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(contents_labels_df['text'])\n",
    "train_x_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "valid_x_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede295c-b012-40c3-991c-df4fc2b02e04",
   "metadata": {},
   "source": [
    "# 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f870128-1735-41da-9274-044b4739d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f65f3-575d-4138-bc0d-cd476320372a",
   "metadata": {},
   "source": [
    "## 4.1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a855fdde-cf4c-40bd-a4c2-2504b0f4dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = train_model(naive_bayes.MultinomialNB(), train_x_count, train_y_encoded, valid_x_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), train_x_tfidf, train_y_encoded, valid_x_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), train_x_tfidf_ngram, train_y_encoded, valid_x_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), train_x_tfidf_ngram_chars, train_y_encoded, valid_x_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2f6b8-d822-4ca2-bdd7-7fd2b654abdd",
   "metadata": {},
   "source": [
    "## 4.2. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9400109c-d790-4acd-9ff6-81535416c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), train_x_count, train_y_encoded, valid_x_count)\n",
    "print(\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), train_x_tfidf, train_y_encoded, valid_x_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), train_x_tfidf_ngram, train_y_encoded, valid_x_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), train_x_tfidf_ngram_chars, train_y_encoded, valid_x_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55118b17-ab31-4068-91df-d1c1d6ebbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier = linear_model.LogisticRegression()\n",
    "lr_classifier.fit(train_x_tfidf, train_y_encoded)\n",
    "validation_predictions = lr_classifier.predict(valid_x_tfidf)\n",
    "\n",
    "print(f'''\n",
    "Model Performance:\n",
    "    Accuracy: {metrics.accuracy_score(validation_predictions, valid_y_encoded)}\n",
    "    Precision: {metrics.precision_score(validation_predictions, valid_y_encoded, average='weighted')}\n",
    "    Recall: {metrics.recall_score(validation_predictions, valid_y_encoded, average='weighted')}\n",
    "    F1: {metrics.f1_score(validation_predictions, valid_y_encoded, average='weighted')}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67b4f2-16ef-4c36-b5b0-1b2a83f022ca",
   "metadata": {},
   "source": [
    "Model Performance:\n",
    "- Accuracy: 0.9733333333333334\n",
    "- Precision: 0.9754666666666667\n",
    "- Recall: 0.9733333333333334\n",
    "- F1: 0.973210922787194"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27471ca-cbbd-4b50-816c-79a38ee6bd19",
   "metadata": {},
   "source": [
    "# 5. Looking at Validation Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80b28d-d352-4d10-a5e8-746d16d9e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573cf8d-a7bc-4040-bffb-e08c58a0740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b55de0-3b40-45f3-8120-faf922ef7daa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_contents = list(valid_x)\n",
    "validation_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79f586-525f-43c3-947f-23b1ca54c0c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_predictions_ints = validation_predictions.tolist()\n",
    "validation_predictions_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b0a20-6bff-4a59-b745-b2e1613a26f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_prediction = random.choice(range(0, len(validation_predictions)))\n",
    "\n",
    "print(f'Prediction:\\n{encoding_map[validation_predictions_ints[check_prediction]]}')\n",
    "print(f'\\nContents:\\n{validation_contents[check_prediction]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b0f7a-b62e-4bba-8a9d-d8271a060559",
   "metadata": {},
   "source": [
    "# 6. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df0611-92c9-4e05-a654-17103f3bbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d902e3f-0b2d-46d4-9343-d03fc61c4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39383543-154f-4d25-b3a8-89c43b3ee0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = '../../files/trained_models/logistic_regression_acc_97_3.sav'\n",
    "pickle.dump(lr_classifier, open(model_file_name,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177691b-e281-451e-a493-ebd4f1fc3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_map_file_name = '../../files/trained_models/encoding_map.sav'\n",
    "pickle.dump(encoding_map, open(encoding_map_file_name,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
